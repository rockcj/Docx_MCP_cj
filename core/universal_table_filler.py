#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é€šç”¨è¡¨æ ¼å¡«å……å™¨ - åŸºäºæ™ºèƒ½åˆ†æçš„è¡¨æ ¼å¡«å……æ‰§è¡Œå™¨
æ”¯æŒä»»æ„æ ¼å¼çš„Wordè¡¨æ ¼æ™ºèƒ½å¡«å……
"""

import json
import logging
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
from docx import Document
from .intelligent_table_analyzer import IntelligentTableAnalyzer

logger = logging.getLogger(__name__)

class UniversalTableFiller:
    """é€šç”¨è¡¨æ ¼å¡«å……å™¨"""
    
    def __init__(self):
        self.analyzer = IntelligentTableAnalyzer()
    
    def analyze_and_get_coordinates(self, file_path: str) -> str:
        """
        åˆ†ææ–‡æ¡£å¹¶è¿”å›åæ ‡ä¿¡æ¯ï¼ˆé‡ç‚¹åŠŸèƒ½ï¼‰
        
        Args:
            file_path: æ–‡æ¡£è·¯å¾„
            
        Returns:
            åæ ‡æ˜ å°„ä¿¡æ¯ï¼Œä¾›AIä½¿ç”¨
        """
        try:
            # åˆ†ææ–‡æ¡£ç»“æ„
            logger.info(f"åˆ†ææ–‡æ¡£ç»“æ„: {file_path}")
            analysis_result = self.analyzer.analyze_document(file_path)
            
            if 'error' in analysis_result:
                return f"æ–‡æ¡£åˆ†æå¤±è´¥: {analysis_result['error']}"
            
            # åˆ›å»ºåæ ‡æ˜ å°„
            logger.info("åˆ›å»ºåæ ‡æ˜ å°„ä¿¡æ¯")
            coordinate_mapping = self.analyzer.create_coordinate_mapping(analysis_result)
            
            return json.dumps(coordinate_mapping, ensure_ascii=False, indent=2)
            
        except Exception as e:
            logger.error(f"åæ ‡åˆ†æå¤±è´¥: {e}")
            return f"åˆ†æå¤±è´¥: {str(e)}"
    
    def get_document_analysis(self, file_path: str) -> str:
        """
        è·å–æ–‡æ¡£åˆ†æç»“æœï¼ˆä¸“æ³¨äºåæ ‡ä¿¡æ¯ï¼‰
        
        Args:
            file_path: æ–‡æ¡£è·¯å¾„
            
        Returns:
            JSONæ ¼å¼çš„åæ ‡åˆ†æç»“æœ
        """
        try:
            # ç›´æ¥è°ƒç”¨åæ ‡åˆ†ææ–¹æ³•
            return self.analyze_and_get_coordinates(file_path)
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£åˆ†æå¤±è´¥: {e}")
            return f"åˆ†æå¤±è´¥: {str(e)}"
    
    def fill_with_coordinates(self, file_path: str, 
                            coordinate_data: Dict[str, Tuple[int, int, int]]) -> str:
        """
        ä½¿ç”¨åæ ‡æ•°æ®ç›´æ¥å¡«å……è¡¨æ ¼
        
        Args:
            file_path: æ–‡æ¡£è·¯å¾„
            coordinate_data: åæ ‡æ•°æ®ï¼Œæ ¼å¼ä¸º {æ•°æ®å†…å®¹: (è¡¨æ ¼ç´¢å¼•, è¡Œç´¢å¼•, åˆ—ç´¢å¼•)}
            
        Returns:
            å¡«å……ç»“æœ
        """
        try:
            result = self._execute_fill_plan(file_path, coordinate_data)
            return self._format_coordinate_result(coordinate_data, result)
            
        except Exception as e:
            logger.error(f"åæ ‡å¡«å……å¤±è´¥: {e}")
            return f"å¡«å……å¤±è´¥: {str(e)}"
    
    def _execute_fill_plan(self, file_path: str, 
                          fill_plan: Dict[str, Tuple[int, int, int]]) -> Dict[str, Any]:
        """
        æ‰§è¡Œå¡«å……è®¡åˆ’
        
        Args:
            file_path: æ–‡æ¡£è·¯å¾„
            fill_plan: å¡«å……è®¡åˆ’
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        try:
            # æ‰“å¼€æ–‡æ¡£
            doc = Document(file_path)
            
            filled_count = 0
            filled_positions = []
            failed_fills = []
            
            # æ‰§è¡Œæ¯ä¸ªå¡«å……æ“ä½œ
            #ï¼ˆè¡¨ï¼Œè¡Œï¼Œåˆ—ï¼‰
            for data_value, (table_idx, row_idx, col_idx) in fill_plan.items():
                try:
                    # éªŒè¯è¡¨æ ¼ç´¢å¼•
                    if table_idx >= len(doc.tables):
                        failed_fills.append({
                            'data': data_value,
                            'position': (table_idx, row_idx, col_idx),
                            'error': f'è¡¨æ ¼ç´¢å¼•è¶…å‡ºèŒƒå›´: {table_idx}'
                        })
                        continue
                    
                    table = doc.tables[table_idx]
                    
                    # éªŒè¯è¡Œåˆ—ç´¢å¼•
                    if row_idx >= len(table.rows):
                        failed_fills.append({
                            'data': data_value,
                            'position': (table_idx, row_idx, col_idx),
                            'error': f'è¡Œç´¢å¼•è¶…å‡ºèŒƒå›´: {row_idx}'
                        })
                        continue
                    
                    if col_idx >= len(table.rows[row_idx].cells):
                        failed_fills.append({
                            'data': data_value,
                            'position': (table_idx, row_idx, col_idx),
                            'error': f'åˆ—ç´¢å¼•è¶…å‡ºèŒƒå›´: {col_idx}'
                        })
                        continue
                    
                    # æ‰§è¡Œå¡«å……
                    cell = table.cell(row_idx, col_idx)
                    original_text = cell.text.strip()
                    
                    # æ£€æŸ¥æ˜¯å¦å·²æœ‰å†…å®¹
                    if original_text and original_text != data_value:
                        logger.warning(f"ä½ç½® ({table_idx}, {row_idx}, {col_idx}) å·²æœ‰å†…å®¹: '{original_text}'ï¼Œå°†è¢«è¦†ç›–ä¸º: '{data_value}'")
                    
                    # å¡«å……æ•°æ®
                    cell.text = str(data_value)
                    filled_count += 1
                    filled_positions.append({
                        'data': data_value,
                        'position': (table_idx, row_idx, col_idx),
                        'original_text': original_text
                    })
                    
                    logger.info(f"æˆåŠŸå¡«å…… '{data_value}' åˆ°ä½ç½® ({table_idx}, {row_idx}, {col_idx})")
                    
                except Exception as e:
                    failed_fills.append({
                        'data': data_value,
                        'position': (table_idx, row_idx, col_idx),
                        'error': str(e)
                    })
                    logger.error(f"å¡«å……å¤±è´¥: '{data_value}' -> ({table_idx}, {row_idx}, {col_idx}): {e}")
            
            # ä¿å­˜æ–‡æ¡£
            doc.save(file_path)
            
            return {
                'success': True,
                'filled_count': filled_count,
                'total_planned': len(fill_plan),
                'filled_positions': filled_positions,
                'failed_fills': failed_fills,
                'success_rate': filled_count / len(fill_plan) if fill_plan else 0
            }
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œå¡«å……è®¡åˆ’å¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'filled_count': 0,
                'failed_fills': []
            }
    
    def _format_analysis_for_ai(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ ¼å¼åŒ–åˆ†æç»“æœä¸ºAIå‹å¥½çš„æ ¼å¼
        
        Args:
            analysis_result: åŸå§‹åˆ†æç»“æœ
            
        Returns:
            AIå‹å¥½çš„æ ¼å¼åŒ–ç»“æœ
        """
        # æå–å…³é”®ä¿¡æ¯
        field_positions = analysis_result.get('field_positions', {})
        empty_positions = analysis_result.get('empty_positions', [])
        fill_rules = analysis_result.get('fill_rules', [])
        
        # åˆ›å»ºç®€åŒ–çš„å­—æ®µæ˜ å°„ï¼ˆä½¿ç”¨æ‚¨è¦æ±‚çš„æ ¼å¼ï¼‰
        simplified_field_map = {}
        for field_name, position in field_positions.items():
            simplified_field_map[field_name] = position
        
        # åˆ›å»ºç©ºä½æ˜ å°„
        empty_map = {}
        for i, position in enumerate(empty_positions):
            empty_map[f'empty_{i+1}'] = position
        
        # åˆ›å»ºå¡«å……è§„åˆ™æ‘˜è¦
        rules_summary = []
        for rule in fill_rules:
            rules_summary.append({
                'field': rule['field'],
                'fill_position': rule['fill_position'],
                'rule_type': rule['rule_type'],
                'confidence': rule['confidence']
            })
        
        return {
            'document_info': analysis_result.get('document_info', {}),
            'field_positions': simplified_field_map,
            'empty_positions': empty_map,
            'fill_rules': rules_summary,
            'ai_instructions': {
                'usage_notes': [
                    '1. æœ‰å­—æ®µå†…å®¹çš„æ ¼å­ä¸å¯ä»¥å¡«',
                    '2. ä¼˜å…ˆä½¿ç”¨å³ä¾§å¡«å……è§„åˆ™',
                    '3. å­—æ®µåä¸‹æ–¹çš„æ ¼å­ä¹Ÿå¯èƒ½å¡«å……æ•°æ®',
                    '4. å­—æ®µåå³ä¾§çš„æ ¼å­é€šå¸¸å¡«å……è¯¥å­—æ®µçš„æ•°æ®',
                    '5. è¿”å›æ ¼å¼: {"æ•°æ®å†…å®¹": (è¡¨æ ¼ç´¢å¼•, è¡Œç´¢å¼•, åˆ—ç´¢å¼•)}'
                ],
                'example_format': {
                    'å¼ ä¸‰': (1, 1, 3),
                    '2023001234': (1, 2, 3),
                    'è®¡ç®—æœºå­¦é™¢': (1, 1, 5)
                }
            },
            'total_tables': analysis_result.get('document_info', {}).get('total_tables', 0),
            'total_fields': len(field_positions),
            'total_empty_positions': len(empty_positions),
            'total_fill_rules': len(fill_rules)
        }
    
    def _format_result(self, analysis_result: Dict[str, Any], 
                      fill_plan: Dict[str, Tuple[int, int, int]], 
                      execution_result: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–æœ€ç»ˆç»“æœ
        
        Args:
            analysis_result: åˆ†æç»“æœ
            fill_plan: å¡«å……è®¡åˆ’
            execution_result: æ‰§è¡Œç»“æœ
            
        Returns:
            æ ¼å¼åŒ–çš„ç»“æœå­—ç¬¦ä¸²
        """
        if not execution_result.get('success', False):
            return f"å¡«å……å¤±è´¥: {execution_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
        
        filled_count = execution_result.get('filled_count', 0)
        total_planned = execution_result.get('total_planned', 0)
        success_rate = execution_result.get('success_rate', 0)
        
        result_parts = [
            f"âœ… æ™ºèƒ½è¡¨æ ¼å¡«å……å®Œæˆ",
            f"ğŸ“Š å¡«å……ç»Ÿè®¡: {filled_count}/{total_planned} ä¸ªå­—æ®µæˆåŠŸå¡«å…… (æˆåŠŸç‡: {success_rate:.1%})"
        ]
        
        # æ·»åŠ æˆåŠŸå¡«å……çš„è¯¦ç»†ä¿¡æ¯
        if execution_result.get('filled_positions'):
            result_parts.append("\nğŸ¯ æˆåŠŸå¡«å……çš„å­—æ®µ:")
            for item in execution_result['filled_positions']:
                data = item['data']
                pos = item['position']
                result_parts.append(f"   â€¢ '{data}' â†’ è¡¨æ ¼{pos[0]}, è¡Œ{pos[1]}, åˆ—{pos[2]}")
        
        # æ·»åŠ å¤±è´¥å¡«å……çš„ä¿¡æ¯
        if execution_result.get('failed_fills'):
            result_parts.append(f"\nâŒ å¡«å……å¤±è´¥çš„å­—æ®µ ({len(execution_result['failed_fills'])}ä¸ª):")
            for item in execution_result['failed_fills']:
                data = item['data']
                pos = item['position']
                error = item['error']
                result_parts.append(f"   â€¢ '{data}' â†’ ä½ç½®{pos}: {error}")
        
        return "\n".join(result_parts)
    
    def _format_coordinate_result(self, coordinate_data: Dict[str, Tuple[int, int, int]], 
                                execution_result: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–åæ ‡å¡«å……ç»“æœ
        
        Args:
            coordinate_data: åæ ‡æ•°æ®
            execution_result: æ‰§è¡Œç»“æœ
            
        Returns:
            æ ¼å¼åŒ–çš„ç»“æœå­—ç¬¦ä¸²
        """
        if not execution_result.get('success', False):
            return f"åæ ‡å¡«å……å¤±è´¥: {execution_result.get('error', 'æœªçŸ¥é”™è¯¯')}"
        
        filled_count = execution_result.get('filled_count', 0)
        total_planned = len(coordinate_data)
        success_rate = execution_result.get('success_rate', 0)
        
        result_parts = [
            f"âœ… åæ ‡è¡¨æ ¼å¡«å……å®Œæˆ",
            f"ğŸ“Š å¡«å……ç»Ÿè®¡: {filled_count}/{total_planned} ä¸ªä½ç½®æˆåŠŸå¡«å…… (æˆåŠŸç‡: {success_rate:.1%})"
        ]
        
        # æ·»åŠ å¡«å……è¯¦æƒ…
        if execution_result.get('filled_positions'):
            result_parts.append("\nğŸ¯ å¡«å……è¯¦æƒ…:")
            for item in execution_result['filled_positions']:
                data = item['data']
                pos = item['position']
                original = item.get('original_text', '')
                if original:
                    result_parts.append(f"   â€¢ '{data}' â†’ è¡¨æ ¼{pos[0]}, è¡Œ{pos[1]}, åˆ—{pos[2]} (åŸå†…å®¹: '{original}')")
                else:
                    result_parts.append(f"   â€¢ '{data}' â†’ è¡¨æ ¼{pos[0]}, è¡Œ{pos[1]}, åˆ—{pos[2]}")
        
        return "\n".join(result_parts)
    
    def intelligent_fill(self, file_path: str, fill_data: Dict[str, Any]) -> str:
        """
        æ™ºèƒ½å¡«å…… - åŸºäºå­—æ®µåè‡ªåŠ¨åŒ¹é…å¡«å……
        
        Args:
            file_path: æ–‡æ¡£è·¯å¾„
            fill_data: å¡«å……æ•°æ®å­—å…¸
            
        Returns:
            å¡«å……ç»“æœä¿¡æ¯
        """
        try:
            # åˆ†ææ–‡æ¡£ç»“æ„
            logger.info(f"æ™ºèƒ½å¡«å……æ–‡æ¡£: {file_path}")
            analysis_result = self.analyzer.analyze_document(file_path)
            
            if 'error' in analysis_result:
                return f"æ–‡æ¡£åˆ†æå¤±è´¥: {analysis_result['error']}"
            
            # è·å–å­—æ®µä½ç½®
            field_positions = analysis_result.get('field_positions', {})
            
            if not field_positions:
                return "æœªæ‰¾åˆ°å¯å¡«å……å­—æ®µ"
            
            # æ™ºèƒ½åŒ¹é…å­—æ®µ
            matched_positions = {}
            unmatched_fields = []
            
            for data_key, data_value in fill_data.items():
                best_match = None
                best_confidence = 0.0
                
                # å°è¯•åŒ¹é…å­—æ®µå
                for field_name, position in field_positions.items():
                    confidence = self._calculate_field_similarity(data_key, field_name)
                    if confidence > best_confidence and confidence > 0.3:  # æœ€ä½åŒ¹é…é˜ˆå€¼
                        best_confidence = confidence
                        best_match = position
                
                if best_match:
                    matched_positions[data_value] = best_match
                else:
                    unmatched_fields.append(data_key)
            
            if not matched_positions:
                return f"æ— æ³•åŒ¹é…ä»»ä½•å­—æ®µã€‚æœªåŒ¹é…å­—æ®µ: {unmatched_fields}"
            
            # æ‰§è¡Œå¡«å……
            result = self._execute_fill_plan(file_path, matched_positions)
            
            # æ„å»ºè¿”å›ä¿¡æ¯
            filled_count = len(matched_positions)
            result_parts = [f"æ™ºèƒ½å¡«å……å®Œæˆï¼Œå…±å¡«å…… {filled_count} ä¸ªå­—æ®µ"]
            
            if unmatched_fields:
                result_parts.append(f"æœªåŒ¹é…å­—æ®µ: {', '.join(unmatched_fields)}")
            
            result_parts.append(f"\nå¡«å……è¯¦æƒ…:")
            for data, pos in matched_positions.items():
                result_parts.append(f"  â€¢ '{data}' â†’ è¡¨æ ¼{pos[0]}, è¡Œ{pos[1]}, åˆ—{pos[2]}")
            
            return "\n".join(result_parts)
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½å¡«å……å¤±è´¥: {e}")
            return f"æ™ºèƒ½å¡«å……å¤±è´¥: {str(e)}"
    
    def _calculate_field_similarity(self, field1: str, field2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå­—æ®µåçš„ç›¸ä¼¼åº¦
        
        Args:
            field1: å­—æ®µå1
            field2: å­—æ®µå2
            
        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
        """
        import difflib
        
        # æ¸…ç†å­—æ®µå
        clean_field1 = field1.replace(' ', '').replace('ã€', '').replace('ï¼š', '')
        clean_field2 = field2.replace(' ', '').replace('ã€', '').replace('ï¼š', '')
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = difflib.SequenceMatcher(None, clean_field1, clean_field2).ratio()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯
        keywords = ['å§“å', 'å­¦å·', 'å­¦é™¢', 'ä¸“ä¸š', 'å®ä¹ ', 'æ—¶é—´', 'å•ä½']
        for keyword in keywords:
            if keyword in clean_field1 and keyword in clean_field2:
                similarity = max(similarity, 0.8)
        
        return similarity
